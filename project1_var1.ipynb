{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from calendar import monthrange\n",
    "from pandas.tseries.offsets import MonthBegin\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file_customers = '/mnt/HC_Volume_18315164/home-jupyter/jupyter-i-tolstihin/olist_customers_dataset.csv'\n",
    "path_to_file_orders = '/mnt/HC_Volume_18315164/home-jupyter/jupyter-i-tolstihin/olist_orders_dataset.csv'\n",
    "path_to_file_order_item = '/mnt/HC_Volume_18315164/home-jupyter/jupyter-i-tolstihin/olist_order_items_dataset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_data = pd.read_csv(path_to_file_customers , sep = ',')\n",
    "order_item_data = pd.read_csv(path_to_file_order_item , sep = ',', parse_dates=['shipping_limit_date'])\n",
    "orders_data = pd.read_csv(path_to_file_orders , sep = ',',parse_dates=['order_purchase_timestamp', 'order_approved_at', 'order_delivered_carrier_date', 'order_delivered_customer_date','order_estimated_delivery_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "customers_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_data.order_status.unique ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(\n",
    "    customers_data, orders_data,\n",
    "    left_on='customer_id',\n",
    "    right_on='customer_id'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_unique_data = df_merged.query(\"order_status == 'delivered'\") \\\n",
    "    .groupby(['customer_unique_id'], as_index = False) \\\n",
    "    .agg({'customer_id' : 'count'}) \\\n",
    "    .query(\"customer_id == 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В первой таблице содержатся данные о всех заказах, совершенных пользователями. А во второй имеется информация об их статусе. Четкого ответа на вопрос, что считать за \"покупку\" нет, так нет уточняющей информации для чего необходимо знать количество клиентов, которые совершали покупку только 1 раз. Изначально, мне казалось, что правильным решением будет отбор заказов, которые завершились оплатой. С другой стороны, заказ мог быть отменен клиентом или магазином, и прибыль компании не изменилась (или, например, не выросла конверсия какого-либо рекламного продвижения и т.д.). Поэтому было принято решение отобрать \"доставленные\" заказы, то есть успешно завершенных заказов, и уже из данного списка отобрать уникальных клиентов, которые не имеют более одного успешно завершенного заказа. Также стоит отметить, что существуют пул незавершенных заказов, которые могут как успешно завершиться, так и отмениться, их мы тоже не будем брать в счёт."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_unique_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Сколько заказов в месяц в среднем не доставляется по разным причинам (вывести детализацию по причинам)? (10 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Немного изучив данные становится понятно, что отследить \"воронку\" движения заказа невозможно, так как при смене статуса заказа, записи не дублируются, а статус изменяется в уже имеющемся номере заказа. По этой причине было принято решение определить \"не доставленный заказ\", как заказ, который не был и не будет доставлен. То есть стоит убрать из нашего среза статусы со статусами \"создан\", \"подтверждён\", \"выставлен счёт\", \"в процессе сборки заказа\", \"отгружен со склада\", так как эти заказы потенциально могут быть доставлены и нет смысла искать в них причины. Также стоит не брать во внимание заказы со статусом \"доставлен\", так как это успешно завершенная сделка. Остаются 2 типа \"недоступен\" и \"отменён\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_data.query(\"order_status == 'unavailable'\").order_delivered_customer_date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_data.query(\"order_status == 'unavailable'\").order_delivered_carrier_date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#проверка влияния дельты на статус заказа для \"недоступно\"\n",
    "orders_data_unavailable = orders_data.query(\"order_status == 'unavailable'\").sort_values('order_purchase_timestamp')\n",
    "orders_data_unavailable['delta'] = orders_data_unavailable.order_approved_at - orders_data_unavailable.order_purchase_timestamp\n",
    "orders_data_unavailable.sort_values('delta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Были проверено, что такие заказы не были доставлены (order_estimated_delivery_date = 'NaT') и не были переданы в службу доставки. Возникла гипотеза влияния количества времени между оформлением заказа и его оплатой на статус. Также возникла гипотеза о зависимости статуса заказа от пользователя (например, отправлен в \"черный список\"). Обе теории не подтвердились, поэтому данные заказы мы объединим под общей причиной \"заказ недоступен\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#проверка влияния дельты на статус заказа для \"досталвено\"\n",
    "orders_data_delivered = orders_data.query(\"order_status == 'delivered'\").sort_values('order_purchase_timestamp')\n",
    "orders_data_delivered['delta'] = orders_data_delivered.order_approved_at - orders_data_delivered.order_purchase_timestamp\n",
    "orders_data_delivered.sort_values('delta', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# отбираем отмененные заказы\n",
    "orders_data_canceled = orders_data.query(\"order_status == 'canceled'\")\n",
    "orders_data_canceled.order_delivered_customer_date.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметно, что у нас имеется 6 случаев, когда заказ был доставлен, но имеет статус \"отменен\". Данные случаи мы также не будем рассматривать, так как они не подходят по нашим условиям (не был и не будет доставлен). Теперь мы имеем 619 случаев того, что заказ не был доставлен по причине отмены, а также 609 случаев \"недоступных\" заказов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_data_canceled = orders_data_canceled.query(\"order_delivered_customer_date == 'NaT'\")\n",
    "orders_data_canceled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_data_canceled_with_item =pd.merge(\n",
    "    orders_data_canceled, order_item_data,\n",
    "    left_on='order_id',\n",
    "    right_on='order_id',\n",
    "    how='inner'\n",
    ")\n",
    "orders_data_canceled_with_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_data_canceled_with_item['delta'] = orders_data_canceled_with_item.order_estimated_delivery_date - orders_data_canceled_with_item.shipping_limit_date\n",
    "orders_data_canceled_with_item.sort_values('delta').head(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дальнейший поиск причин упирается только в гипотезы и догадки, так как данных не достаточно, для того, чтобы классифицировать отмененные заказы. Мне удалось найти только 8 записей с аномалиями - крайняя дата доставки продавцом товара в логистическую службу больше крайней даты доставки заказа, что могло повлиять на отмену заказа (а могло и нет). По этой причине было принято решение ограничиться двумя \"поверхностными\" причинами почему заказ не был доставлен."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_data_canceled['month'] = orders_data_canceled.order_estimated_delivery_date.dt.month\n",
    "orders_data_canceled['year'] = orders_data_canceled.order_estimated_delivery_date.dt.year\n",
    "orders_data_unavailable['month'] = orders_data_unavailable.order_estimated_delivery_date.dt.month\n",
    "orders_data_unavailable['year'] = orders_data_unavailable.order_estimated_delivery_date.dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_data_canceled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_data_unavailable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#неизвестно\n",
    "count_unavailable = orders_data_unavailable.groupby(['year','month'], as_index = False) \\\n",
    "    .agg({'order_id' : 'count'}) \\\n",
    "    .groupby(['month'], as_index = False) \\\n",
    "    .agg({'order_id' : 'mean'}) \\\n",
    "    .sort_values('month')\n",
    "count_unavailable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#отменено\n",
    "count_canceled = orders_data_canceled.groupby(['year','month'], as_index = False) \\\n",
    "    .agg({'order_id' : 'count'}) \\\n",
    "    .groupby(['month'], as_index = False) \\\n",
    "    .agg({'order_id' : 'mean'}) \\\n",
    "    .round(1) \\\n",
    "    .sort_values('month')\n",
    "count_canceled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "\n",
    "rects1 = ax.bar(count_canceled.month - 0.3/2, count_canceled.order_id, 0.3, label='canceled')\n",
    "rects2 = ax.bar(count_canceled.month + 0.3/2, count_unavailable.order_id, 0.3, label='gunavailable')\n",
    "ax.set_title('Среднее количество недоставленных заказов в разбивке по месяцам')\n",
    "ax.set_xticks(count_canceled.month)\n",
    "#ax.set_xticklabels(count_canceled.month)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Было найдено среднее количество заказов, которые не доставили, в разбивке по месяцам (если компании присуща определенная сезонность). А в месяц в среднем количество составит:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Среднее количество заказов, которые не доставили по причине \"заказа отменён\":', round(count_canceled.order_id.mean(),2))\n",
    "print('Среднее количество заказов, которые не доставили по причине \"неизвестно\":', round(count_unavailable.order_id.mean(),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .\n",
    "# 3. По каждому товару определить, в какой день недели товар чаще всего покупается. (7 баллов)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_item_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_product_orders = pd.merge(\n",
    "    order_item_data, orders_data,\n",
    "    left_on='order_id',\n",
    "    right_on='order_id',\n",
    "    how = 'left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_product_orders = data_product_orders.query(\"order_approved_at != 'NaT'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном случае покупкой будем считать факт оплаты товара, так как, если имеется какая-либо зависимость товара от покупки, то стоит отследить в какой день недели была произведена оплата."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_product_orders['week_day'] = data_product_orders.order_approved_at.dt.day_name ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_product_orders = data_product_orders.groupby(['product_id', 'week_day'], as_index = False ) \\\n",
    "    .agg({'order_id' : 'count'}) \\\n",
    "    .sort_values(['product_id', 'order_id'], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# уникальный айди продукта и его максимальное количество продаж\n",
    "product_max = data_product_orders.groupby(['product_id'], as_index = False) \\\n",
    "    .agg({'order_id' : 'max'}) \\\n",
    "    .rename(columns = {'order_id' : 'max_order_id'})\n",
    "product_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_product_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_product_orders = pd.merge(\n",
    "    data_product_orders, product_max,\n",
    "    left_on='product_id',\n",
    "    right_on='product_id',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_product_orders = data_product_orders.loc[data_product_orders['order_id'] == data_product_orders['max_order_id']]\n",
    "del data_product_orders['order_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_product_orders.pivot(index = 'product_id', columns = 'week_day', values = 'max_order_id').fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном случае, необходимо было сохранить записи, где несколько максимумов. Для этого был создан отдельный датафрейм, в котором вычислен максимум покупок в разбивке по продукту и номеру недели, а после удалены все значения из исходного датафрейма в группировке по продукту и номеру недели, где число покупок не совпадало с максимумом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Сколько у каждого из пользователей в среднем покупок в неделю (по месяцам)? \n",
    "#Не стоит забывать, что внутри месяца может быть не целое количество недель. \n",
    "#Например, в ноябре 2021 года 4,28 недели. И внутри метрики это нужно учесть. (8 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном задании покупка также будет фиксироваться за пользователем, если он совершил оплату, а дата покупки - дата подтверждения оплаты товара"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_customers = df_merged.query(\"order_approved_at != 'NaT'\")\n",
    "all_customers = all_customers.assign(weeks_in_month = round(all_customers.order_approved_at.dt.days_in_month / 7,2))\n",
    "all_customers = all_customers.assign(month = all_customers.order_approved_at.dt.month)\n",
    "all_customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_count_in_week = all_customers.groupby(['customer_unique_id', 'month'], as_index = False ) \\\n",
    "    .agg({'order_id' : 'count'}) \\\n",
    "    .sort_values(['customer_unique_id'], ascending=[True]) \\\n",
    "    .rename(columns = {'order_id' : 'count_order_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#для подсчёта среднего значения количества недель в месяц, с учётом високосного года\n",
    "count_weeks_in_month = all_customers.groupby(['month'], as_index = False) \\\n",
    "                                    .agg({'weeks_in_month' : 'mean'})\n",
    "count_weeks_in_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_count_in_week = pd.merge(\n",
    "    customers_count_in_week, count_weeks_in_month,\n",
    "    left_on='month',\n",
    "    right_on='month',\n",
    "    how='left'\n",
    ")\n",
    "customers_count_in_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_count_in_week = customers_count_in_week.assign(count_order_in_week = round(customers_count_in_week.count_order_id/customers_count_in_week.weeks_in_month,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_count_in_week.pivot(index = 'customer_unique_id', columns = 'month', values = 'count_order_in_week').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.1. Выполните когортный анализ пользователей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.2. В период с января по декабрь выявите когорту с самым высоким retention на 3-й месяц."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(\n",
    "    customers_data, orders_data,\n",
    "    left_on='customer_id',\n",
    "    right_on='customer_id'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_merged.query(\"order_approved_at != 'NaT'\")\n",
    "start_date = min(df_merged.order_approved_at)\n",
    "start_date = (start_date + pd.offsets.MonthEnd(0) - pd.offsets.MonthBegin()).to_pydatetime().date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_merged.assign(date_purchase = (df_merged.order_approved_at + pd.offsets.MonthEnd(0) - pd.offsets.MonthBegin()).dt.date)\n",
    "df_merged = df_merged.assign(delta = ((df_merged.date_purchase - start_date) /  np.timedelta64 ( 1 , 'M')).apply(pd.np.ceil))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_first_purchase = df_merged.groupby(['customer_unique_id'], as_index = False).agg({'date_purchase':'min'}).rename(columns = {'date_purchase' : 'first_date_purchase'})\n",
    "# для подсчёта количества клиентов \n",
    "data_first_purchase = data_first_purchase.merge(df_merged.groupby(['customer_unique_id'], as_index = False).agg({'customer_id':'count'}),\n",
    "    left_on='customer_unique_id',\n",
    "    right_on='customer_unique_id',\n",
    "    how = 'left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.date_purchase = pd.to_datetime(df_merged.date_purchase)\n",
    "data_first_purchase.first_date_purchase = pd.to_datetime(data_first_purchase.first_date_purchase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Уникальные временные интервалы\n",
    "y = df_merged.date_purchase.min().year\n",
    "m = df_merged.date_purchase.min().month\n",
    "d = df_merged.date_purchase.min().day\n",
    "data_date = []\n",
    "month_year = []\n",
    "number_month = []\n",
    "data_date.append((datetime.datetime.strptime(f\"{y}-{m}-{d}\", '%Y-%m-%d').date()))\n",
    "number_month.append(f\"#1\")\n",
    "month_year.append(f\"{m}-{y}\")\n",
    "for i in range(int(df_merged.delta.max())):\n",
    "    m += 1\n",
    "    if ((m-1)%12 == 0):\n",
    "        m = 1\n",
    "        y = y + 1\n",
    "    data_date.append((datetime.datetime.strptime(f\"{y}-{m}-{d}\", '%Y-%m-%d').date()))\n",
    "    month_year.append(f\"{m}-{y}\")\n",
    "    number_month.append(f\"#{i+2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retention = np.zeros((len(data_date),len(data_date))) \n",
    "# отбираем уникальные айди по первой покупке за каждый месяц, после чего присоединяем по очереди тех клиентов, кто вернулся\n",
    "# и считаем их количество, подливая в матрицу\n",
    "for i in range(len(data_date)):\n",
    "    for j in range(i, len(data_date)):\n",
    "            retention[i][j-i] = int(pd.merge(data_first_purchase.query(f\"first_date_purchase == '{data_date[i]}'\") \\\n",
    "                            .groupby(['customer_unique_id'], as_index = False) \\\n",
    "                            .agg({'customer_id':'count'}),\n",
    "                     df_merged.query(f\"date_purchase == '{data_date[j]}'\") \\\n",
    "                            .groupby(['customer_unique_id'], as_index = False) \\\n",
    "                            .agg({'customer_id':'count'}),\n",
    "                     left_on='customer_unique_id',\n",
    "                     right_on='customer_unique_id',\n",
    "                     how = 'inner') \\\n",
    "                .agg({'customer_id_y' : 'count'})[0])\n",
    "            if (i>0):\n",
    "                retention[i][-i:] = 'NaN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#переводим в доли\n",
    "for i in range(len(data_date)):\n",
    "    k = retention[i][0]\n",
    "    for j in range(len(data_date)):\n",
    "        if (retention[i][0] == 0):\n",
    "            continue\n",
    "        else:\n",
    "            retention[i][j] = round(retention[i][j]/k,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#конвертируем в pandas\n",
    "data_retention = pd.DataFrame(data=retention, \n",
    "                              index=month_year, \n",
    "                              columns=number_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_retention_style = (data_retention\n",
    "            .style\n",
    "            .set_caption('Retention - table')  # добавляем подпись\n",
    "            .background_gradient(cmap='viridis')  # раскрашиваем ячейки по столбцам\n",
    "            .highlight_null('white')  # делаем белый фон для значений NaN\n",
    "            .format(\"{:.2%}\", na_rep=\"\"))  # числа форматируем как проценты, NaN заменяем на пустоту\n",
    "data_retention_style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пользователи нашего сервиса в большинстве случаев совершают 1 покупку, и не возвращаются под своим уникальным id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. RFM - сегментация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "До расчётов составлящих R, F и M необходимо отметить несколько нюансов. Сегментация будет проводиться только из клиентов, которые получили свои заказы (delivered). Время от последней покупки будет считаться от даты подтверждения заказа (order_approved_at) до последней даты подтвержденного заказа- самого позднего клиента (можно было и посчитать и до текущей даты, но от этого сегментация не изменится, так как будут подобраны аналогичные границы метрик). Количество покупок будет рассчитано как количество чеков (будем объединять несколько товаров в один чек), так как это позволит нам отобрать клиентов с высокой частотой. А если имеются оптовые закупщики, то это можно будет понять по их товарообороту. Сумма покупок будет считаться как сумма по полю \"price\", так как, в случае, когда покупается несколько товаров одного айди, то записи дублируются (нет необходимости умножать на количество товаров в чеке)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_data = pd.read_csv(path_to_file_customers , sep = ',')\n",
    "order_item_data = pd.read_csv(path_to_file_order_item , sep = ',', parse_dates=['shipping_limit_date'])\n",
    "orders_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.merge(\n",
    "    customers_data, orders_data,\n",
    "    left_on='customer_id',\n",
    "    right_on='customer_id'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.merge(\n",
    "    all_data, order_item_data,\n",
    "    left_on='order_id',\n",
    "    right_on='order_id'\n",
    ")\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_segment = pd.merge(\n",
    "    customers_data, orders_data,\n",
    "    left_on='customer_id',\n",
    "    right_on='customer_id'\n",
    ")\n",
    "r_segment = r_segment.query(\"order_status == 'delivered' and order_approved_at != 'NaT'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r_segment\n",
    "last_date = r_segment.groupby(['customer_unique_id'], as_index = False) \\\n",
    "            .agg({'order_approved_at':'max'}).order_approved_at.max() + pd.to_timedelta('1 days 00:00:00')\n",
    "r_segment = r_segment.groupby(['customer_unique_id'], as_index = False) \\\n",
    "            .agg({'order_approved_at':'max'})\n",
    "r_segment = r_segment.assign(delta = last_date - r_segment.order_approved_at)\n",
    "r_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "f_segment = all_data.query(\"order_status == 'delivered'\") \\\n",
    "                    .groupby(['customer_unique_id'], as_index = False) \\\n",
    "                    .agg({'order_id':'nunique'}) \\\n",
    "                    .rename(columns = {'order_id' : 'count_order'})\n",
    "f_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_segment = all_data.query(\"order_status == 'delivered'\") \\\n",
    "    .groupby(['customer_unique_id'], as_index = False) \\\n",
    "    .agg({'price':'sum'}) \\\n",
    "    .rename(columns = {'price' : 'trade_turnover'})\n",
    "m_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm_segment = pd.merge(\n",
    "    r_segment[['customer_unique_id', 'delta']], \n",
    "                        pd.merge(\n",
    "                            f_segment, m_segment,\n",
    "                            left_on='customer_unique_id',\n",
    "                            right_on='customer_unique_id'\n",
    "                                ),\n",
    "    left_on='customer_unique_id',\n",
    "    right_on='customer_unique_id'\n",
    ")\n",
    "rfm_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rfm_segment.delta.quantile(0))\n",
    "print(rfm_segment.delta.quantile(0.33))\n",
    "print(rfm_segment.delta.quantile(0.66))\n",
    "print(rfm_segment.delta.quantile(0.99))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Всего будет выделено 3 кластера от 1 до 3, где 3 - положительный для компании (больше всего денег, высокая частота или недавняя покупка). Разделение сегмента по дате последней покупки произведено поровну между максимальным большой разницей и минимальной разницей (1/3 на сегмент). Недостаточно данных для определения целевой аудитории сервиса, чтобы определить границы кластеров, исходя из логики. По этой причине, границы были найдены через квантиль"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r\n",
    "rfm_segment['R'] = pd.cut(rfm_segment.delta, \n",
    "                bins = [pd.to_timedelta('0 days 00:00:00'), \n",
    "                        pd.to_timedelta(rfm_segment.delta.quantile(0.33)),\n",
    "                        pd.to_timedelta(rfm_segment.delta.quantile(0.66)),\n",
    "                        pd.to_timedelta(rfm_segment.delta.quantile(1))], \n",
    "                labels = ['3' , \n",
    "                          '2', \n",
    "                          '1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm_segment.groupby(['count_order'], as_index = False) \\\n",
    "            .agg({'customer_unique_id' : 'count'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В сегменте по частоте не представляется возможным разбить самый наполненный клиентами сегмент - 1 покупка. Поэтому этот сегмент будет принимать значение \"1\", как самый популярный. Аналогично отобран второй сегмент - две покупки, третий сегмент - больше двух покупок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f\n",
    "rfm_segment['F'] = pd.cut(rfm_segment.count_order, \n",
    "                bins = [0, \n",
    "                        1,\n",
    "                        2,\n",
    "                        200], \n",
    "                labels = ['1' , \n",
    "                          '2', \n",
    "                          '3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m\n",
    "rfm_segment['M'] = pd.cut(rfm_segment.trade_turnover, \n",
    "                bins = [0.0, \n",
    "                        rfm_segment.trade_turnover.quantile(0.5),\n",
    "                        rfm_segment.trade_turnover.quantile(0.8),\n",
    "                        rfm_segment.trade_turnover.quantile(1)], \n",
    "                labels = ['1' , \n",
    "                          '2', \n",
    "                          '3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сегмент \"M\" был разделён по аналогу с ABC-классификатором. Худшая половина пользователей - это \"1\", лучшие 20% - \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm_segment.drop(['delta','count_order','trade_turnover'], axis= 1 , inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm_segment.R = rfm_segment.R.astype('int32')\n",
    "rfm_segment.F = rfm_segment.F.astype('int32')\n",
    "rfm_segment.M = rfm_segment.M.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
